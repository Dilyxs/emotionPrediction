{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafad043-8bbb-41ed-9def-0e1be8283750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import idx2numpy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c2e272-5e54-4d85-97e4-2e70fdd62ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimages = []\n",
    "trainlabels = []\n",
    "index = 0\n",
    "mode = \"Train\"\n",
    "Map= {}\n",
    "emotions = os.listdir(f'emotionfolder/{mode}')\n",
    "for emotion in emotions:\n",
    "    Map[index]=emotion\n",
    "\n",
    "    if emotion==\"affectnet\" or emotion==\"emotionfolder\":\n",
    "        continue\n",
    "    \n",
    "    files =os.listdir(f'emotionfolder/{mode}/{emotion}')\n",
    "    for file in files:\n",
    "        try:\n",
    "            filepath =f'emotionfolder/{mode}/{emotion}/{file}'\n",
    "            trainimages.append(filepath)\n",
    "            trainlabels.append(index)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e425ebf9-24fc-4a22-aa8b-56b2ce268e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimages = []\n",
    "testlabels = []\n",
    "index = 0\n",
    "mode = 'Test'\n",
    "emotions = os.listdir(f'emotionfolder/{mode}')\n",
    "for emotion in emotions:\n",
    "    if emotion==\"affectnet\" or emotion==\"emotionfolder\":\n",
    "        continue\n",
    "    \n",
    "    files =os.listdir(f'emotionfolder/{mode}/{emotion}')\n",
    "    for file in files:\n",
    "        try:\n",
    "            img = f'emotionfolder/{mode}/{emotion}/{file}'\n",
    "            testimages.append(img)\n",
    "            testlabels.append(index)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab06481-d765-4c59-8bf0-b3a7e1316bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split is rougly 60/40 right now, need to make it ~80/10/10\n",
    "trainimages.extend(testimages)\n",
    "trainlabels.extend(testlabels)\n",
    "\n",
    "trainimages_final = []\n",
    "trainlabel_final = []\n",
    "testimages_final = []\n",
    "testlabel_final = []\n",
    "valimages_final = []\n",
    "vallabels_final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac94b68-7508-414a-bade-4b18288506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(trainimages)-1):\n",
    "    num = random.randint(1,10)\n",
    "\n",
    "    if 1<=num<=8:\n",
    "        trainimages_final.append(trainimages[i])\n",
    "        trainlabel_final.append(trainlabels[i])\n",
    "\n",
    "    elif num==9:\n",
    "        testimages_final.append(trainimages[i])\n",
    "        testlabel_final.append(trainlabels[i])\n",
    "\n",
    "    else:\n",
    "        valimages_final.append(trainimages[i])\n",
    "        vallabels_final.append(trainlabels[i])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69809b9a-39ef-45f0-b774-654a2eb957c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224,224)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba741e8-fa8d-44f6-92b5-a33e622d1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(target_size), \n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 50% chance of a horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90be8d46-6712-45fe-930f-3d1f5f6e7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imageslink, label,transformation_maker):\n",
    "        super().__init__()\n",
    "        self.imageslink = imageslink\n",
    "        self.label = label\n",
    "        self.transformation_maker = transformation_maker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.imageslink[idx])\n",
    "        img =  self.transformation_maker(img)\n",
    "\n",
    "        return img, self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733fe46f-2bec-424e-80e8-e1f5f974578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = MyDataset(trainimages_final, trainlabel_final, transform_train)\n",
    "testDataset = MyDataset(testimages_final, testlabel_final, transforms_test)\n",
    "valDataset = MyDataset(valimages_final, vallabels_final, transforms_test)\n",
    "trainloader = DataLoader(trainDataset, batch_size=256, shuffle=True, num_workers=10, pin_memory=True)\n",
    "testloader = DataLoader(testDataset, batch_size=256, shuffle=True, num_workers=10, pin_memory=True)\n",
    "valloader = DataLoader(valDataset, batch_size=256, shuffle=True, num_workers=10, pin_memory=True)\n",
    "#8outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb493fb-a2be-4145-943d-570eaa89b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnArchitecture(nn.Module):\n",
    "    def __init__(self, is_grayscale, output_size, num_layers, hidden_size,  kernel_size, image_size=96):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size=1 if is_grayscale else 3\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.imagesize = image_size\n",
    "        self.kernelsize = kernel_size\n",
    "        self.map = {3:1, 5:2, 7:3}\n",
    "        self.Network = []\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if i==0:\n",
    "                self.Network.append(nn.Conv2d(self.input_size, self.hidden_size, kernel_size=self.kernelsize, padding=self.map[self.kernelsize]))\n",
    "                self.Network.append(nn.ReLU())\n",
    "                self.Network.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            else:\n",
    "                self.Network.append(nn.Conv2d(self.hidden_size, self.hidden_size, kernel_size=self.kernelsize, padding=self.map[self.kernelsize]))\n",
    "                self.Network.append(nn.ReLU())\n",
    "                self.Network.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.features = nn.Sequential(*self.Network)\n",
    "        sampletorch = torch.randn(1, self.input_size, self.imagesize, self.imagesize)\n",
    "        self.dummy_size = self.features(sampletorch).numel()\n",
    "\n",
    "        self.classifier = nn.Linear(self.dummy_size, self.output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)#no relu here since criterion and loss will take care of it!\n",
    "                                                                              \n",
    "\n",
    "                                                                              \n",
    "                                                            \n",
    "                                                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3839245-7435-4946-895d-290624cb8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7fdce9-45a3-4fd1-b05d-dc6018b9056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32,64,128,256])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [2,4,6])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [16, 64, 128])\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-3, 1e-4, 1e-5])\n",
    "    epochs = trial.suggest_categorical(\"epochs\", [50, 75, 100])\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-2, 1e-3, 1e-4])   \n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3,5,7])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    trainloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    valloader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CnnArchitecture(False, 8, num_layers, hidden_size, kernel_size)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    testloss = []\n",
    "\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        for x,y in trainloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            training_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in valloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                test_loss+=loss.item()\n",
    "                total += y.size(0)\n",
    "                probability, predicted = torch.max(y_pred.data, 1)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                \n",
    "        if i%20==0 or i==epochs-1: \n",
    "            avg_train_loss = training_loss / len(trainloader)\n",
    "            avg_test_loss = test_loss / len(valloader)\n",
    "            accuracy = (100 * correct) / total\n",
    "    \n",
    "            print(f\"Epoch num: {i}\")\n",
    "            print(f\"  Train Loss: {avg_train_loss}\")\n",
    "            print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "            print(f\"  Accuracy:   {accuracy}%\")\n",
    "            print(\"--------------------\")\n",
    "            testloss.append(avg_test_loss)\n",
    "            trial.report(avg_test_loss, i)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return testloss[-1]#want to minimize testloss!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bbc31b4-fb79-4e11-88c5-429e366555fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 08:34:00,863] A new study created in memory with name: no-name-2ee787cb-024a-491c-93d8-bbf5e09ba882\n",
      "Exception in thread Thread-5 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/usr/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/_utils/pin_memory.py\"\u001b[0m, line \u001b[35m52\u001b[0m, in \u001b[35m_pin_memory_loop\u001b[0m\n",
      "    \u001b[31mdo_one_step\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/_utils/pin_memory.py\"\u001b[0m, line \u001b[35m28\u001b[0m, in \u001b[35mdo_one_step\u001b[0m\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \u001b[35m\"/usr/lib/python3.13/multiprocessing/queues.py\"\u001b[0m, line \u001b[35m120\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "    return \u001b[31m_ForkingPickler.loads\u001b[0m\u001b[1;31m(res)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/multiprocessing/reductions.py\"\u001b[0m, line \u001b[35m541\u001b[0m, in \u001b[35mrebuild_storage_fd\u001b[0m\n",
      "    fd = df.detach()\n",
      "  File \u001b[35m\"/usr/lib/python3.13/multiprocessing/resource_sharer.py\"\u001b[0m, line \u001b[35m57\u001b[0m, in \u001b[35mdetach\u001b[0m\n",
      "    with \u001b[31m_resource_sharer.get_connection\u001b[0m\u001b[1;31m(self._id)\u001b[0m as conn:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/usr/lib/python3.13/multiprocessing/resource_sharer.py\"\u001b[0m, line \u001b[35m86\u001b[0m, in \u001b[35mget_connection\u001b[0m\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \u001b[35m\"/usr/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m519\u001b[0m, in \u001b[35mClient\u001b[0m\n",
      "    c = SocketClient(address)\n",
      "  File \u001b[35m\"/usr/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m647\u001b[0m, in \u001b[35mSocketClient\u001b[0m\n",
      "    \u001b[31ms.connect\u001b[0m\u001b[1;31m(address)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[Errno 2] No such file or directory\u001b[0m\n",
      "[W 2025-11-13 08:34:04,248] Trial 0 failed with parameters: {'batch_size': 256, 'num_layers': 6, 'hidden_size': 128, 'lr': 0.001, 'epochs': 50, 'weight_decay': 0.001, 'kernel_size': 7} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5341/3571969484.py\", line 30, in objective\n",
      "    y_pred = model(x)\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_5341/2069626457.py\", line 32, in forward\n",
      "    x=self.features(x)\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py\", line 548, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py\", line 543, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ~~~~~~~~^\n",
      "        input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-13 08:34:04,252] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     28\u001b[39m y = y.to(device)\n\u001b[32m     29\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m loss = criterion(y_pred, y)\n\u001b[32m     32\u001b[39m training_loss+=loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mCnnArchitecture.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     x=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classifier(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc632c6-699a-431f-b723-05b2ce5c3e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstudy\u001b[49m.best_params.items():\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "for key, value in study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8152993f-2a87-4fee-b8f6-cbeebdc1f9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * 400 / 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "56bb062b-80ea-459b-a45e-63109741a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now build model with best found params\n",
    "best_params = study.best_params\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "num_layers = best_params[\"num_layers\"]\n",
    "hidden_size = best_params[\"hidden_size\"]\n",
    "lr = best_params[\"lr\"]\n",
    "epochs = best_params[\"epochs\"]\n",
    "kernel_size = best_params[\"kernel_size\"]\n",
    "weight_decay = best_params[\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d22582e-b8c3-4fe8-9001-fb6969e6978b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m compressedtrainlabels.extend(vallabels_final)\n\u001b[32m      8\u001b[39m compressedDataset =  MyDataset(compressedtrain, compressedtrainlabels, transform_train)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m trainloader = DataLoader(compressedDataset, batch_size=\u001b[43mbatch_size\u001b[49m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers=\u001b[32m8\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m model = CnnArchitecture(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[32m8\u001b[39m, num_layers, hidden_size, kernel_size)\n",
      "\u001b[31mNameError\u001b[39m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "#custom dataset with both train && val\n",
    "compressedtrain = []\n",
    "compressedtrainlabels = []\n",
    "compressedtrain.extend(trainimages_final)\n",
    "compressedtrain.extend(valimages_final)\n",
    "compressedtrainlabels.extend(trainlabel_final)\n",
    "compressedtrainlabels.extend(vallabels_final)\n",
    "compressedDataset =  MyDataset(compressedtrain, compressedtrainlabels, transform_train)\n",
    "\n",
    "\n",
    "\n",
    "trainloader = DataLoader(compressedDataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CnnArchitecture(False, 8, num_layers, hidden_size, kernel_size)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "testloss = []\n",
    "\n",
    "\n",
    "for i in range(150):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for x,y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        training_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in valloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss+=loss.item()\n",
    "            total += y.size(0)\n",
    "            probability, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    if i%20==0 or i==epochs-1: \n",
    "        avg_train_loss = training_loss / len(trainloader)\n",
    "        avg_test_loss = test_loss / len(valloader)\n",
    "        accuracy = (100 * correct) / total\n",
    "\n",
    "        print(f\"Epoch num: {i}\")\n",
    "        print(f\"  Train Loss: {avg_train_loss}\")\n",
    "        print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "        print(f\"  Accuracy:   {accuracy}%\")\n",
    "        print(\"--------------------\")\n",
    "        testloss.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c7437ce1-1889-481c-8104-c62b7e1348dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_emotion_prediction.pkl']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"cnn_emotion_prediction.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "05ea16b3-40d5-40eb-b9c0-cba5c12cc3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = joblib.load('cnn_emotion_prediction.pkl')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe962d-6aa8-4f1e-a14d-ec0be841af26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523d6eb-26e6-4230-8d1f-b742a8233d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let us test it on testDataset, model is not performant at all, training from scratch is not worth it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dacc1413-dd23-4b62-a828-7544333c5ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Loss:  1.7339561184247334\n",
      "  Accuracy:   27.995971802618328%\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "for x,y in testloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    test_loss+=loss.item()\n",
    "    total+=y.size(0)\n",
    "    _, prediction = torch.max(y_pred, 1)\n",
    "    correct+=(prediction==y).sum().item()\n",
    "\n",
    "avg_test_loss = test_loss / len(testloader)\n",
    "accuracy = (100 * correct) / total\n",
    "\n",
    "print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "print(f\"  Accuracy:   {accuracy}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe179a5-67d2-49a1-88d5-77aabbe55192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e86eec-4af7-4ad9-adb3-312c61dcc3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603aa194-00aa-4c55-b143-7161bbb0c8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19f3cd21-c359-48fb-8416-2e858abd21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM HERE ON OUT, IT IS NOT BUILDING A MODEL FROM SCRATH FOR THIS PROBLEM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e69732-c599-4cfd-96d3-a432bb80b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2581dd93-71d4-4ee2-8f5c-0d38eb7b3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastpreviouslayer = model.fc.in_features\n",
    "output=8\n",
    "model.fc = nn.Linear(lastpreviouslayer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb5dfad-1700-4f1f-8bb2-198185b53ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d3eab1-52b4-4008-b9b0-46d91eb1396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d26752f-3f68-4c4e-8d2f-5828a1157a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size=trial.suggest_categorical(\"batch_size\", [128])\n",
    "    epochs = trial.suggest_categorical(\"epochs\", [16,32,64])\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-3, 1e-4, 1e-5])\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-5, 1e-7, 0])\n",
    "    model_size = trial.suggest_categorical(\"model_size\", [18,34,50])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    output=8\n",
    "    if model_size==18:\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "    elif model_size==32:\n",
    "        model = torchvision.models.resnet34(pretrained=True)\n",
    "    else:\n",
    "        model = torchvision.models.resnet50(pretrained=True)\n",
    "    lastpreviouslayer = model.fc.in_features\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=False\n",
    "    model.fc = nn.Linear(lastpreviouslayer, output)\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    trainloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    valloader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    testloss = []\n",
    "\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        for x,y in trainloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            training_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in valloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                test_loss+=loss.item()\n",
    "                total += y.size(0)\n",
    "                probability, predicted = torch.max(y_pred.data, 1)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                \n",
    "        if i%20==0 or i==epochs-1: \n",
    "            avg_train_loss = training_loss / len(trainloader)\n",
    "            avg_test_loss = test_loss / len(valloader)\n",
    "            accuracy = (100 * correct) / total\n",
    "    \n",
    "            print(f\"Epoch num: {i}\")\n",
    "            print(f\"  Train Loss: {avg_train_loss}\")\n",
    "            print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "            print(f\"  Accuracy:   {accuracy}%\")\n",
    "            print(\"--------------------\")\n",
    "            testloss.append(avg_test_loss)\n",
    "            trial.report(avg_test_loss, i)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return testloss[-1]#want to minimize testloss!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99130657-d594-42a9-b49e-3f5b47035ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:10:22,348] A new study created in memory with name: no-name-7b04b167-fa59-48a5-975d-86613d7dcc25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 2.1084921496609845\n",
      "  Test Loss:  2.05455673734347\n",
      "  Accuracy:   20.67951649787651%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:16:16,548] Trial 0 finished with value: 1.7375248124202092 and parameters: {'batch_size': 128, 'epochs': 16, 'lr': 1e-05, 'weight_decay': 0, 'model_size': 18}. Best is trial 0 with value: 1.7375248124202092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 15\n",
      "  Train Loss: 1.7392577069501083\n",
      "  Test Loss:  1.7375248124202092\n",
      "  Accuracy:   34.20450833061091%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilyxs/programming/python/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 2.041928700481852\n",
      "  Test Loss:  2.0213674853245416\n",
      "  Accuracy:   21.006207121855603%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.5512117116401594\n",
      "  Test Loss:  1.5670379102230072\n",
      "  Accuracy:   43.515191114015025%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 20:46:19,806] Trial 1 finished with value: 1.4954314529895782 and parameters: {'batch_size': 128, 'epochs': 32, 'lr': 1e-05, 'weight_decay': 1e-07, 'model_size': 34}. Best is trial 1 with value: 1.4954314529895782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 31\n",
      "  Train Loss: 1.4752018054326375\n",
      "  Test Loss:  1.4954314529895782\n",
      "  Accuracy:   45.279320483502126%\n",
      "--------------------\n",
      "Epoch num: 0\n",
      "  Train Loss: 1.5701719957093399\n",
      "  Test Loss:  1.4454486320416133\n",
      "  Accuracy:   43.64586736360666%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.1919004501154025\n",
      "  Test Loss:  1.3366331507762272\n",
      "  Accuracy:   48.676902972884676%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:16:30,621] Trial 2 finished with value: 1.2907888889312744 and parameters: {'batch_size': 128, 'epochs': 32, 'lr': 0.001, 'weight_decay': 1e-05, 'model_size': 50}. Best is trial 2 with value: 1.2907888889312744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 31\n",
      "  Train Loss: 1.1486962366228302\n",
      "  Test Loss:  1.2907888889312744\n",
      "  Accuracy:   50.31035609278014%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d084161-14ef-470c-9ed3-d741f1f655ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'epochs': 32,\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 1e-05,\n",
       " 'model_size': 50}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37aa34-2612-430b-b053-1c70a0eaafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the new model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3c66b62-fa3a-4d14-a485-bc2e270fd3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 1.562836433450381\n",
      "  Test Loss:  1.4063928922017415\n",
      "  Accuracy:   46.128716105847765%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.1974625547106068\n",
      "  Test Loss:  1.298115645845731\n",
      "  Accuracy:   50.44103234237178%\n",
      "--------------------\n",
      "Epoch num: 40\n",
      "  Train Loss: 1.1375562998776634\n",
      "  Test Loss:  1.2693762977917988\n",
      "  Accuracy:   51.38843515191114%\n",
      "--------------------\n",
      "Epoch num: 60\n",
      "  Train Loss: 1.1072659293810527\n",
      "  Test Loss:  1.2743211040894191\n",
      "  Accuracy:   50.40836327997386%\n",
      "--------------------\n",
      "Epoch num: 63\n",
      "  Train Loss: 1.1021915295471747\n",
      "  Test Loss:  1.2686743239561717\n",
      "  Accuracy:   51.09441359032996%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "output=8\n",
    "batch_size=128\n",
    "epochs=64\n",
    "lr=0.001\n",
    "weight_decay=1e-5\n",
    "model_size=50\n",
    "if model_size==18:\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "elif model_size==32:\n",
    "    model = torchvision.models.resnet34(pretrained=True)\n",
    "else:\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "lastpreviouslayer = model.fc.in_features\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.fc = nn.Linear(lastpreviouslayer, output)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "valloader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "testloss = []\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for x,y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        training_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in valloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss+=loss.item()\n",
    "            total += y.size(0)\n",
    "            probability, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    if i%20==0 or i==epochs-1: \n",
    "        avg_train_loss = training_loss / len(trainloader)\n",
    "        avg_test_loss = test_loss / len(valloader)\n",
    "        accuracy = (100 * correct) / total\n",
    "\n",
    "        print(f\"Epoch num: {i}\")\n",
    "        print(f\"  Train Loss: {avg_train_loss}\")\n",
    "        print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "        print(f\"  Accuracy:   {accuracy}%\")\n",
    "        print(\"--------------------\")\n",
    "        testloss.append(avg_test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb020c62-0c69-4d24-9b0f-0af5441c216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet_fine_tuned.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"resnet_fine_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e442665-b1c2-4205-b997-c28a1593b043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8040584-9c13-4a03-9c7a-40f1216a13ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c6ed2-5bc3-43fe-9c4c-2528d4037813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeda0e-1082-4799-a4cd-210688dfde28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1da14-dff2-4554-abd0-a5980f95a99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c556a6-1d4d-4d8f-bb2f-fe955203567d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b4bd8-9dd6-4767-a3d2-15a7fed38c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c4ecb-168e-4f6b-a515-d603e609a708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79ba5974-9ea4-4e19-8d23-3a063fd06815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testrun for prediction\n",
    "img = Image.open('emotionfolder/Train/anger/image0022969.jpg')\n",
    "img = transforms_test(img)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c916d460-fe9e-4b57-9221-c4dd454e0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EmotionMap = {v:k for k,v in Map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fd6b71c2-88e6-47de-a4fc-004337c897e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'happy': 4,\n",
       " 'neutral': 5,\n",
       " 'sad': 6,\n",
       " 'surprise': 7}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmotionMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ca95ab5-eb8b-46d7-b45d-bf491353112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to define this into helper file later on...\n",
    "def Predict(imgpath, model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    PredictionEmotionMap =EmotionMap.copy()\n",
    "    img = Image.open(imgpath)\n",
    "    img = transforms_test(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(img)\n",
    "\n",
    "    prediction_confidence_array = torch.nn.functional.softmax(y_pred, dim=1)[0].cpu().numpy()\n",
    "    for i in range(len(prediction_confidence_array)):\n",
    "        emotion = Map[i]\n",
    "        PredictionEmotionMap[emotion] = prediction_confidence_array[i]\n",
    "\n",
    "    return PredictionEmotionMap\n",
    "    #how would I convert confidence to a 100%scale cause it ain't like that right now no?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "32e1f815-4cbd-4500-9ee0-986e965b1766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': np.float32(0.10275879),\n",
       " 'contempt': np.float32(0.10070733),\n",
       " 'disgust': np.float32(0.09365553),\n",
       " 'fear': np.float32(0.10301596),\n",
       " 'happy': np.float32(0.16819917),\n",
       " 'neutral': np.float32(0.15946205),\n",
       " 'sad': np.float32(0.13645828),\n",
       " 'surprise': np.float32(0.13574292)}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict('emotionfolder/Train/anger/image0022969.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbf3df-f993-425a-8f75-3ac301c60e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
