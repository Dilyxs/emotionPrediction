{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fafad043-8bbb-41ed-9def-0e1be8283750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import idx2numpy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import os\n",
    "import random\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95c2e272-5e54-4d85-97e4-2e70fdd62ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimages = []\n",
    "trainlabels = []\n",
    "index = 0\n",
    "mode = \"Train\"\n",
    "Map= {}\n",
    "emotions = os.listdir(f'emotionfolder/{mode}')\n",
    "for emotion in emotions:\n",
    "    Map[index]=emotion\n",
    "\n",
    "    if emotion==\"affectnet\" or emotion==\"emotionfolder\":\n",
    "        continue\n",
    "    \n",
    "    files =os.listdir(f'emotionfolder/{mode}/{emotion}')\n",
    "    for file in files:\n",
    "        try:\n",
    "            filepath =f'emotionfolder/{mode}/{emotion}/{file}'\n",
    "            trainimages.append(filepath)\n",
    "            trainlabels.append(index)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e425ebf9-24fc-4a22-aa8b-56b2ce268e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimages = []\n",
    "testlabels = []\n",
    "index = 0\n",
    "mode = 'Test'\n",
    "emotions = os.listdir(f'emotionfolder/{mode}')\n",
    "for emotion in emotions:\n",
    "    if emotion==\"affectnet\" or emotion==\"emotionfolder\":\n",
    "        continue\n",
    "    \n",
    "    files =os.listdir(f'emotionfolder/{mode}/{emotion}')\n",
    "    for file in files:\n",
    "        try:\n",
    "            img = f'emotionfolder/{mode}/{emotion}/{file}'\n",
    "            testimages.append(img)\n",
    "            testlabels.append(index)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ab06481-d765-4c59-8bf0-b3a7e1316bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split is rougly 60/40 right now, need to make it ~80/10/10\n",
    "trainimages.extend(testimages)\n",
    "trainlabels.extend(testlabels)\n",
    "\n",
    "trainimages_final = []\n",
    "trainlabel_final = []\n",
    "testimages_final = []\n",
    "testlabel_final = []\n",
    "valimages_final = []\n",
    "vallabels_final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ac94b68-7508-414a-bade-4b18288506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(trainimages)-1):\n",
    "    num = random.randint(1,10)\n",
    "\n",
    "    if 1<=num<=8:\n",
    "        trainimages_final.append(trainimages[i])\n",
    "        trainlabel_final.append(trainlabels[i])\n",
    "\n",
    "    elif num==9:\n",
    "        testimages_final.append(trainimages[i])\n",
    "        testlabel_final.append(trainlabels[i])\n",
    "\n",
    "    else:\n",
    "        valimages_final.append(trainimages[i])\n",
    "        vallabels_final.append(trainlabels[i])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69809b9a-39ef-45f0-b774-654a2eb957c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (96,96)\n",
    "mean = [0.5,0.5,0.5]\n",
    "std = [0.5,0.5,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eba741e8-fa8d-44f6-92b5-a33e622d1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(target_size),\n",
    "    transforms.RandomVerticalFlip(10),\n",
    "    transforms.RandomHorizontalFlip(9),\n",
    "    transforms.RandomRotation(12),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.24),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "90be8d46-6712-45fe-930f-3d1f5f6e7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imageslink, label,transformation_maker):\n",
    "        super().__init__()\n",
    "        self.imageslink = imageslink\n",
    "        self.label = label\n",
    "        self.transformation_maker = transformation_maker\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.imageslink[idx])\n",
    "        img =  self.transformation_maker(img)\n",
    "\n",
    "        return img, self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "733fe46f-2bec-424e-80e8-e1f5f974578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = MyDataset(trainimages_final, trainlabel_final, transform_train)\n",
    "testDataset = MyDataset(testimages_final, testlabel_final, transforms_test)\n",
    "valDataset = MyDataset(valimages_final, vallabels_final, transforms_test)\n",
    "trainloader = DataLoader(trainDataset, batch_size=256, shuffle=True, num_workers=16, pin_memory=True)\n",
    "testloader = DataLoader(testDataset, batch_size=256, shuffle=True, num_workers=16, pin_memory=True)\n",
    "valloader = DataLoader(valDataset, batch_size=256, shuffle=True, num_workers=16, pin_memory=True)\n",
    "#8outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ffb493fb-a2be-4145-943d-570eaa89b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnArchitecture(nn.Module):\n",
    "    def __init__(self, is_grayscale, output_size, num_layers, hidden_size,  kernel_size, image_size=96):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size=1 if is_grayscale else 3\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.imagesize = image_size\n",
    "        self.kernelsize = kernel_size\n",
    "        self.map = {3:1, 5:2, 7:3}\n",
    "        self.Network = []\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if i==0:\n",
    "                self.Network.append(nn.Conv2d(self.input_size, self.hidden_size, kernel_size=self.kernelsize, padding=self.map[self.kernelsize]))\n",
    "                self.Network.append(nn.ReLU())\n",
    "                self.Network.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            else:\n",
    "                self.Network.append(nn.Conv2d(self.hidden_size, self.hidden_size, kernel_size=self.kernelsize, padding=self.map[self.kernelsize]))\n",
    "                self.Network.append(nn.ReLU())\n",
    "                self.Network.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.features = nn.Sequential(*self.Network)\n",
    "        sampletorch = torch.randn(1, self.input_size, self.imagesize, self.imagesize)\n",
    "        self.dummy_size = self.features(sampletorch).numel()\n",
    "\n",
    "        self.classifier = nn.Linear(self.dummy_size, self.output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)#no relu here since criterion and loss will take care of it!\n",
    "                                                                              \n",
    "\n",
    "                                                                              \n",
    "                                                            \n",
    "                                                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c3839245-7435-4946-895d-290624cb8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e060d53-d582-4d04-9506-eee1c4526364",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnArchitecture(False, 8, 3, 32)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7ce278c-66df-4f67-ad34-549dba57c61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 2.0206\n",
      "  Test Loss:  2.0373\n",
      "  Accuracy:   19.15%\n",
      "--------------------\n",
      "Epoch num: 1\n",
      "  Train Loss: 1.9652\n",
      "  Test Loss:  2.0550\n",
      "  Accuracy:   18.55%\n",
      "--------------------\n",
      "Epoch num: 2\n",
      "  Train Loss: 1.9225\n",
      "  Test Loss:  2.0008\n",
      "  Accuracy:   19.28%\n",
      "--------------------\n",
      "Epoch num: 3\n",
      "  Train Loss: 1.8754\n",
      "  Test Loss:  2.0658\n",
      "  Accuracy:   19.84%\n",
      "--------------------\n",
      "Epoch num: 4\n",
      "  Train Loss: 1.7964\n",
      "  Test Loss:  1.9075\n",
      "  Accuracy:   23.61%\n",
      "--------------------\n",
      "Epoch num: 5\n",
      "  Train Loss: 1.7209\n",
      "  Test Loss:  1.8237\n",
      "  Accuracy:   27.78%\n",
      "--------------------\n",
      "Epoch num: 6\n",
      "  Train Loss: 1.6677\n",
      "  Test Loss:  1.8666\n",
      "  Accuracy:   27.15%\n",
      "--------------------\n",
      "Epoch num: 7\n",
      "  Train Loss: 1.6317\n",
      "  Test Loss:  1.8217\n",
      "  Accuracy:   27.58%\n",
      "--------------------\n",
      "Epoch num: 8\n",
      "  Train Loss: 1.6098\n",
      "  Test Loss:  1.8448\n",
      "  Accuracy:   26.65%\n",
      "--------------------\n",
      "Epoch num: 9\n",
      "  Train Loss: 1.5898\n",
      "  Test Loss:  1.7992\n",
      "  Accuracy:   28.11%\n",
      "--------------------\n",
      "Epoch num: 10\n",
      "  Train Loss: 1.5742\n",
      "  Test Loss:  1.8048\n",
      "  Accuracy:   27.78%\n",
      "--------------------\n",
      "Epoch num: 11\n",
      "  Train Loss: 1.5468\n",
      "  Test Loss:  1.8892\n",
      "  Accuracy:   28.27%\n",
      "--------------------\n",
      "Epoch num: 12\n",
      "  Train Loss: 1.5309\n",
      "  Test Loss:  1.8346\n",
      "  Accuracy:   28.21%\n",
      "--------------------\n",
      "Epoch num: 13\n",
      "  Train Loss: 1.5120\n",
      "  Test Loss:  1.8261\n",
      "  Accuracy:   27.51%\n",
      "--------------------\n",
      "Epoch num: 14\n",
      "  Train Loss: 1.5267\n",
      "  Test Loss:  1.8444\n",
      "  Accuracy:   27.48%\n",
      "--------------------\n",
      "Epoch num: 15\n",
      "  Train Loss: 1.4886\n",
      "  Test Loss:  1.9373\n",
      "  Accuracy:   25.43%\n",
      "--------------------\n",
      "Epoch num: 16\n",
      "  Train Loss: 1.4870\n",
      "  Test Loss:  1.8403\n",
      "  Accuracy:   27.98%\n",
      "--------------------\n",
      "Epoch num: 17\n",
      "  Train Loss: 1.4790\n",
      "  Test Loss:  1.8638\n",
      "  Accuracy:   28.54%\n",
      "--------------------\n",
      "Epoch num: 18\n",
      "  Train Loss: 1.4680\n",
      "  Test Loss:  1.8509\n",
      "  Accuracy:   28.01%\n",
      "--------------------\n",
      "Epoch num: 19\n",
      "  Train Loss: 1.4542\n",
      "  Test Loss:  1.8179\n",
      "  Accuracy:   27.94%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.4517\n",
      "  Test Loss:  1.8941\n",
      "  Accuracy:   27.08%\n",
      "--------------------\n",
      "Epoch num: 21\n",
      "  Train Loss: 1.4413\n",
      "  Test Loss:  1.9151\n",
      "  Accuracy:   27.48%\n",
      "--------------------\n",
      "Epoch num: 22\n",
      "  Train Loss: 1.4328\n",
      "  Test Loss:  1.8536\n",
      "  Accuracy:   27.22%\n",
      "--------------------\n",
      "Epoch num: 23\n",
      "  Train Loss: 1.4238\n",
      "  Test Loss:  1.7280\n",
      "  Accuracy:   29.10%\n",
      "--------------------\n",
      "Epoch num: 24\n",
      "  Train Loss: 1.4108\n",
      "  Test Loss:  1.7724\n",
      "  Accuracy:   27.98%\n",
      "--------------------\n",
      "Epoch num: 25\n",
      "  Train Loss: 1.4153\n",
      "  Test Loss:  1.7516\n",
      "  Accuracy:   28.67%\n",
      "--------------------\n",
      "Epoch num: 26\n",
      "  Train Loss: 1.4131\n",
      "  Test Loss:  1.9790\n",
      "  Accuracy:   25.63%\n",
      "--------------------\n",
      "Epoch num: 27\n",
      "  Train Loss: 1.4012\n",
      "  Test Loss:  1.8772\n",
      "  Accuracy:   28.14%\n",
      "--------------------\n",
      "Epoch num: 28\n",
      "  Train Loss: 1.3995\n",
      "  Test Loss:  1.8819\n",
      "  Accuracy:   28.41%\n",
      "--------------------\n",
      "Epoch num: 29\n",
      "  Train Loss: 1.3866\n",
      "  Test Loss:  1.7972\n",
      "  Accuracy:   28.67%\n",
      "--------------------\n",
      "Epoch num: 30\n",
      "  Train Loss: 1.3880\n",
      "  Test Loss:  1.9229\n",
      "  Accuracy:   26.98%\n",
      "--------------------\n",
      "Epoch num: 31\n",
      "  Train Loss: 1.4003\n",
      "  Test Loss:  2.0117\n",
      "  Accuracy:   24.60%\n",
      "--------------------\n",
      "Epoch num: 32\n",
      "  Train Loss: 1.3792\n",
      "  Test Loss:  1.8995\n",
      "  Accuracy:   26.65%\n",
      "--------------------\n",
      "Epoch num: 33\n",
      "  Train Loss: 1.3703\n",
      "  Test Loss:  1.8558\n",
      "  Accuracy:   27.74%\n",
      "--------------------\n",
      "Epoch num: 34\n",
      "  Train Loss: 1.3609\n",
      "  Test Loss:  1.8916\n",
      "  Accuracy:   27.74%\n",
      "--------------------\n",
      "Epoch num: 35\n",
      "  Train Loss: 1.3737\n",
      "  Test Loss:  1.7805\n",
      "  Accuracy:   29.20%\n",
      "--------------------\n",
      "Epoch num: 36\n",
      "  Train Loss: 1.3624\n",
      "  Test Loss:  1.8554\n",
      "  Accuracy:   28.08%\n",
      "--------------------\n",
      "Epoch num: 37\n",
      "  Train Loss: 1.3580\n",
      "  Test Loss:  1.8654\n",
      "  Accuracy:   28.11%\n",
      "--------------------\n",
      "Epoch num: 38\n",
      "  Train Loss: 1.3553\n",
      "  Test Loss:  2.0023\n",
      "  Accuracy:   25.46%\n",
      "--------------------\n",
      "Epoch num: 39\n",
      "  Train Loss: 1.3510\n",
      "  Test Loss:  1.8393\n",
      "  Accuracy:   28.17%\n",
      "--------------------\n",
      "Epoch num: 40\n",
      "  Train Loss: 1.3427\n",
      "  Test Loss:  1.9922\n",
      "  Accuracy:   25.53%\n",
      "--------------------\n",
      "Epoch num: 41\n",
      "  Train Loss: 1.3479\n",
      "  Test Loss:  1.8219\n",
      "  Accuracy:   28.87%\n",
      "--------------------\n",
      "Epoch num: 42\n",
      "  Train Loss: 1.3485\n",
      "  Test Loss:  1.8129\n",
      "  Accuracy:   28.01%\n",
      "--------------------\n",
      "Epoch num: 43\n",
      "  Train Loss: 1.3324\n",
      "  Test Loss:  1.8924\n",
      "  Accuracy:   29.23%\n",
      "--------------------\n",
      "Epoch num: 44\n",
      "  Train Loss: 1.3378\n",
      "  Test Loss:  1.8126\n",
      "  Accuracy:   29.03%\n",
      "--------------------\n",
      "Epoch num: 45\n",
      "  Train Loss: 1.3365\n",
      "  Test Loss:  1.7895\n",
      "  Accuracy:   29.27%\n",
      "--------------------\n",
      "Epoch num: 46\n",
      "  Train Loss: 1.3334\n",
      "  Test Loss:  1.8279\n",
      "  Accuracy:   28.97%\n",
      "--------------------\n",
      "Epoch num: 47\n",
      "  Train Loss: 1.3275\n",
      "  Test Loss:  1.7860\n",
      "  Accuracy:   29.79%\n",
      "--------------------\n",
      "Epoch num: 48\n",
      "  Train Loss: 1.3250\n",
      "  Test Loss:  1.8227\n",
      "  Accuracy:   28.97%\n",
      "--------------------\n",
      "Epoch num: 49\n",
      "  Train Loss: 1.3208\n",
      "  Test Loss:  2.0109\n",
      "  Accuracy:   25.86%\n",
      "--------------------\n",
      "Epoch num: 50\n",
      "  Train Loss: 1.3202\n",
      "  Test Loss:  1.8212\n",
      "  Accuracy:   29.96%\n",
      "--------------------\n",
      "Epoch num: 51\n",
      "  Train Loss: 1.3119\n",
      "  Test Loss:  1.9700\n",
      "  Accuracy:   26.98%\n",
      "--------------------\n",
      "Epoch num: 52\n",
      "  Train Loss: 1.3085\n",
      "  Test Loss:  2.1488\n",
      "  Accuracy:   25.50%\n",
      "--------------------\n",
      "Epoch num: 53\n",
      "  Train Loss: 1.3151\n",
      "  Test Loss:  1.8722\n",
      "  Accuracy:   28.64%\n",
      "--------------------\n",
      "Epoch num: 54\n",
      "  Train Loss: 1.3164\n",
      "  Test Loss:  1.8502\n",
      "  Accuracy:   29.40%\n",
      "--------------------\n",
      "Epoch num: 55\n",
      "  Train Loss: 1.3088\n",
      "  Test Loss:  1.7697\n",
      "  Accuracy:   30.92%\n",
      "--------------------\n",
      "Epoch num: 56\n",
      "  Train Loss: 1.3086\n",
      "  Test Loss:  1.7129\n",
      "  Accuracy:   31.05%\n",
      "--------------------\n",
      "Epoch num: 57\n",
      "  Train Loss: 1.3060\n",
      "  Test Loss:  1.7763\n",
      "  Accuracy:   29.96%\n",
      "--------------------\n",
      "Epoch num: 58\n",
      "  Train Loss: 1.3098\n",
      "  Test Loss:  1.9328\n",
      "  Accuracy:   26.88%\n",
      "--------------------\n",
      "Epoch num: 59\n",
      "  Train Loss: 1.2969\n",
      "  Test Loss:  1.8018\n",
      "  Accuracy:   29.27%\n",
      "--------------------\n",
      "Epoch num: 60\n",
      "  Train Loss: 1.3059\n",
      "  Test Loss:  1.8623\n",
      "  Accuracy:   27.65%\n",
      "--------------------\n",
      "Epoch num: 61\n",
      "  Train Loss: 1.2987\n",
      "  Test Loss:  1.8119\n",
      "  Accuracy:   30.69%\n",
      "--------------------\n",
      "Epoch num: 62\n",
      "  Train Loss: 1.3003\n",
      "  Test Loss:  1.8460\n",
      "  Accuracy:   29.30%\n",
      "--------------------\n",
      "Epoch num: 63\n",
      "  Train Loss: 1.2866\n",
      "  Test Loss:  1.8743\n",
      "  Accuracy:   30.42%\n",
      "--------------------\n",
      "Epoch num: 64\n",
      "  Train Loss: 1.2939\n",
      "  Test Loss:  1.8307\n",
      "  Accuracy:   29.99%\n",
      "--------------------\n",
      "Epoch num: 65\n",
      "  Train Loss: 1.2861\n",
      "  Test Loss:  1.8742\n",
      "  Accuracy:   29.27%\n",
      "--------------------\n",
      "Epoch num: 66\n",
      "  Train Loss: 1.2965\n",
      "  Test Loss:  1.8106\n",
      "  Accuracy:   31.75%\n",
      "--------------------\n",
      "Epoch num: 67\n",
      "  Train Loss: 1.2905\n",
      "  Test Loss:  1.7768\n",
      "  Accuracy:   30.75%\n",
      "--------------------\n",
      "Epoch num: 68\n",
      "  Train Loss: 1.2842\n",
      "  Test Loss:  1.9156\n",
      "  Accuracy:   29.60%\n",
      "--------------------\n",
      "Epoch num: 69\n",
      "  Train Loss: 1.2917\n",
      "  Test Loss:  1.7542\n",
      "  Accuracy:   32.34%\n",
      "--------------------\n",
      "Epoch num: 70\n",
      "  Train Loss: 1.2812\n",
      "  Test Loss:  1.8984\n",
      "  Accuracy:   30.32%\n",
      "--------------------\n",
      "Epoch num: 71\n",
      "  Train Loss: 1.2800\n",
      "  Test Loss:  1.9255\n",
      "  Accuracy:   28.27%\n",
      "--------------------\n",
      "Epoch num: 72\n",
      "  Train Loss: 1.2851\n",
      "  Test Loss:  1.8790\n",
      "  Accuracy:   29.60%\n",
      "--------------------\n",
      "Epoch num: 73\n",
      "  Train Loss: 1.2801\n",
      "  Test Loss:  1.8954\n",
      "  Accuracy:   27.88%\n",
      "--------------------\n",
      "Epoch num: 74\n",
      "  Train Loss: 1.2786\n",
      "  Test Loss:  1.7901\n",
      "  Accuracy:   31.45%\n",
      "--------------------\n",
      "Epoch num: 75\n",
      "  Train Loss: 1.2700\n",
      "  Test Loss:  1.8000\n",
      "  Accuracy:   30.82%\n",
      "--------------------\n",
      "Epoch num: 76\n",
      "  Train Loss: 1.2739\n",
      "  Test Loss:  1.8555\n",
      "  Accuracy:   30.32%\n",
      "--------------------\n",
      "Epoch num: 77\n",
      "  Train Loss: 1.2740\n",
      "  Test Loss:  1.8503\n",
      "  Accuracy:   30.69%\n",
      "--------------------\n",
      "Epoch num: 78\n",
      "  Train Loss: 1.2701\n",
      "  Test Loss:  1.8686\n",
      "  Accuracy:   31.22%\n",
      "--------------------\n",
      "Epoch num: 79\n",
      "  Train Loss: 1.2685\n",
      "  Test Loss:  2.0053\n",
      "  Accuracy:   28.17%\n",
      "--------------------\n",
      "Epoch num: 80\n",
      "  Train Loss: 1.2739\n",
      "  Test Loss:  1.9013\n",
      "  Accuracy:   30.46%\n",
      "--------------------\n",
      "Epoch num: 81\n",
      "  Train Loss: 1.2710\n",
      "  Test Loss:  1.8287\n",
      "  Accuracy:   30.42%\n",
      "--------------------\n",
      "Epoch num: 82\n",
      "  Train Loss: 1.2669\n",
      "  Test Loss:  1.8714\n",
      "  Accuracy:   30.89%\n",
      "--------------------\n",
      "Epoch num: 83\n",
      "  Train Loss: 1.2634\n",
      "  Test Loss:  1.7664\n",
      "  Accuracy:   33.10%\n",
      "--------------------\n",
      "Epoch num: 84\n",
      "  Train Loss: 1.2517\n",
      "  Test Loss:  1.9343\n",
      "  Accuracy:   31.35%\n",
      "--------------------\n",
      "Epoch num: 85\n",
      "  Train Loss: 1.2594\n",
      "  Test Loss:  1.8841\n",
      "  Accuracy:   30.79%\n",
      "--------------------\n",
      "Epoch num: 86\n",
      "  Train Loss: 1.2657\n",
      "  Test Loss:  1.9695\n",
      "  Accuracy:   28.44%\n",
      "--------------------\n",
      "Epoch num: 87\n",
      "  Train Loss: 1.2590\n",
      "  Test Loss:  1.8814\n",
      "  Accuracy:   29.30%\n",
      "--------------------\n",
      "Epoch num: 88\n",
      "  Train Loss: 1.2519\n",
      "  Test Loss:  1.8510\n",
      "  Accuracy:   30.32%\n",
      "--------------------\n",
      "Epoch num: 89\n",
      "  Train Loss: 1.2629\n",
      "  Test Loss:  1.8966\n",
      "  Accuracy:   30.26%\n",
      "--------------------\n",
      "Epoch num: 90\n",
      "  Train Loss: 1.2624\n",
      "  Test Loss:  1.8829\n",
      "  Accuracy:   28.87%\n",
      "--------------------\n",
      "Epoch num: 91\n",
      "  Train Loss: 1.2560\n",
      "  Test Loss:  1.9540\n",
      "  Accuracy:   29.60%\n",
      "--------------------\n",
      "Epoch num: 92\n",
      "  Train Loss: 1.2594\n",
      "  Test Loss:  1.8751\n",
      "  Accuracy:   30.26%\n",
      "--------------------\n",
      "Epoch num: 93\n",
      "  Train Loss: 1.2552\n",
      "  Test Loss:  1.7457\n",
      "  Accuracy:   32.01%\n",
      "--------------------\n",
      "Epoch num: 94\n",
      "  Train Loss: 1.2523\n",
      "  Test Loss:  1.8793\n",
      "  Accuracy:   30.42%\n",
      "--------------------\n",
      "Epoch num: 95\n",
      "  Train Loss: 1.2585\n",
      "  Test Loss:  1.8761\n",
      "  Accuracy:   31.48%\n",
      "--------------------\n",
      "Epoch num: 96\n",
      "  Train Loss: 1.2520\n",
      "  Test Loss:  1.8174\n",
      "  Accuracy:   31.88%\n",
      "--------------------\n",
      "Epoch num: 97\n",
      "  Train Loss: 1.2475\n",
      "  Test Loss:  1.9748\n",
      "  Accuracy:   28.01%\n",
      "--------------------\n",
      "Epoch num: 98\n",
      "  Train Loss: 1.2452\n",
      "  Test Loss:  1.9062\n",
      "  Accuracy:   30.16%\n",
      "--------------------\n",
      "Epoch num: 99\n",
      "  Train Loss: 1.2380\n",
      "  Test Loss:  1.9227\n",
      "  Accuracy:   29.13%\n",
      "--------------------\n",
      "Epoch num: 100\n",
      "  Train Loss: 1.2427\n",
      "  Test Loss:  1.9201\n",
      "  Accuracy:   30.13%\n",
      "--------------------\n",
      "Epoch num: 101\n",
      "  Train Loss: 1.2447\n",
      "  Test Loss:  1.8965\n",
      "  Accuracy:   29.66%\n",
      "--------------------\n",
      "Epoch num: 102\n",
      "  Train Loss: 1.2443\n",
      "  Test Loss:  1.8865\n",
      "  Accuracy:   30.19%\n",
      "--------------------\n",
      "Epoch num: 103\n",
      "  Train Loss: 1.2411\n",
      "  Test Loss:  1.9981\n",
      "  Accuracy:   29.63%\n",
      "--------------------\n",
      "Epoch num: 104\n",
      "  Train Loss: 1.2448\n",
      "  Test Loss:  1.7965\n",
      "  Accuracy:   32.77%\n",
      "--------------------\n",
      "Epoch num: 105\n",
      "  Train Loss: 1.2361\n",
      "  Test Loss:  1.9265\n",
      "  Accuracy:   30.89%\n",
      "--------------------\n",
      "Epoch num: 106\n",
      "  Train Loss: 1.2327\n",
      "  Test Loss:  1.8769\n",
      "  Accuracy:   32.01%\n",
      "--------------------\n",
      "Epoch num: 107\n",
      "  Train Loss: 1.2391\n",
      "  Test Loss:  2.1052\n",
      "  Accuracy:   26.36%\n",
      "--------------------\n",
      "Epoch num: 108\n",
      "  Train Loss: 1.2453\n",
      "  Test Loss:  1.9358\n",
      "  Accuracy:   30.92%\n",
      "--------------------\n",
      "Epoch num: 109\n",
      "  Train Loss: 1.2390\n",
      "  Test Loss:  1.8805\n",
      "  Accuracy:   29.96%\n",
      "--------------------\n",
      "Epoch num: 110\n",
      "  Train Loss: 1.2306\n",
      "  Test Loss:  1.9241\n",
      "  Accuracy:   28.01%\n",
      "--------------------\n",
      "Epoch num: 111\n",
      "  Train Loss: 1.2380\n",
      "  Test Loss:  1.7590\n",
      "  Accuracy:   32.74%\n",
      "--------------------\n",
      "Epoch num: 112\n",
      "  Train Loss: 1.2289\n",
      "  Test Loss:  1.8764\n",
      "  Accuracy:   31.91%\n",
      "--------------------\n",
      "Epoch num: 113\n",
      "  Train Loss: 1.2259\n",
      "  Test Loss:  1.8225\n",
      "  Accuracy:   31.28%\n",
      "--------------------\n",
      "Epoch num: 114\n",
      "  Train Loss: 1.2247\n",
      "  Test Loss:  1.8889\n",
      "  Accuracy:   30.62%\n",
      "--------------------\n",
      "Epoch num: 115\n",
      "  Train Loss: 1.2374\n",
      "  Test Loss:  1.7955\n",
      "  Accuracy:   32.71%\n",
      "--------------------\n",
      "Epoch num: 116\n",
      "  Train Loss: 1.2318\n",
      "  Test Loss:  1.7703\n",
      "  Accuracy:   33.50%\n",
      "--------------------\n",
      "Epoch num: 117\n",
      "  Train Loss: 1.2300\n",
      "  Test Loss:  1.8566\n",
      "  Accuracy:   31.75%\n",
      "--------------------\n",
      "Epoch num: 118\n",
      "  Train Loss: 1.2251\n",
      "  Test Loss:  1.7806\n",
      "  Accuracy:   32.94%\n",
      "--------------------\n",
      "Epoch num: 119\n",
      "  Train Loss: 1.2267\n",
      "  Test Loss:  1.8325\n",
      "  Accuracy:   31.98%\n",
      "--------------------\n",
      "Epoch num: 120\n",
      "  Train Loss: 1.2304\n",
      "  Test Loss:  1.8311\n",
      "  Accuracy:   32.28%\n",
      "--------------------\n",
      "Epoch num: 121\n",
      "  Train Loss: 1.2327\n",
      "  Test Loss:  1.8270\n",
      "  Accuracy:   32.44%\n",
      "--------------------\n",
      "Epoch num: 122\n",
      "  Train Loss: 1.2234\n",
      "  Test Loss:  1.7497\n",
      "  Accuracy:   32.87%\n",
      "--------------------\n",
      "Epoch num: 123\n",
      "  Train Loss: 1.2259\n",
      "  Test Loss:  1.7361\n",
      "  Accuracy:   33.53%\n",
      "--------------------\n",
      "Epoch num: 124\n",
      "  Train Loss: 1.2171\n",
      "  Test Loss:  1.7978\n",
      "  Accuracy:   32.24%\n",
      "--------------------\n",
      "Epoch num: 125\n",
      "  Train Loss: 1.2337\n",
      "  Test Loss:  1.7685\n",
      "  Accuracy:   32.14%\n",
      "--------------------\n",
      "Epoch num: 126\n",
      "  Train Loss: 1.2233\n",
      "  Test Loss:  1.9176\n",
      "  Accuracy:   31.08%\n",
      "--------------------\n",
      "Epoch num: 127\n",
      "  Train Loss: 1.2212\n",
      "  Test Loss:  1.8012\n",
      "  Accuracy:   32.44%\n",
      "--------------------\n",
      "Epoch num: 128\n",
      "  Train Loss: 1.2139\n",
      "  Test Loss:  1.8409\n",
      "  Accuracy:   32.14%\n",
      "--------------------\n",
      "Epoch num: 129\n",
      "  Train Loss: 1.2211\n",
      "  Test Loss:  1.7778\n",
      "  Accuracy:   32.18%\n",
      "--------------------\n",
      "Epoch num: 130\n",
      "  Train Loss: 1.2238\n",
      "  Test Loss:  1.8415\n",
      "  Accuracy:   32.54%\n",
      "--------------------\n",
      "Epoch num: 131\n",
      "  Train Loss: 1.2207\n",
      "  Test Loss:  1.8266\n",
      "  Accuracy:   32.94%\n",
      "--------------------\n",
      "Epoch num: 132\n",
      "  Train Loss: 1.2140\n",
      "  Test Loss:  1.7486\n",
      "  Accuracy:   34.09%\n",
      "--------------------\n",
      "Epoch num: 133\n",
      "  Train Loss: 1.2035\n",
      "  Test Loss:  1.8823\n",
      "  Accuracy:   32.61%\n",
      "--------------------\n",
      "Epoch num: 134\n",
      "  Train Loss: 1.2254\n",
      "  Test Loss:  1.8876\n",
      "  Accuracy:   31.88%\n",
      "--------------------\n",
      "Epoch num: 135\n",
      "  Train Loss: 1.2289\n",
      "  Test Loss:  1.8873\n",
      "  Accuracy:   31.78%\n",
      "--------------------\n",
      "Epoch num: 136\n",
      "  Train Loss: 1.2167\n",
      "  Test Loss:  1.8162\n",
      "  Accuracy:   33.70%\n",
      "--------------------\n",
      "Epoch num: 137\n",
      "  Train Loss: 1.2122\n",
      "  Test Loss:  1.7286\n",
      "  Accuracy:   35.35%\n",
      "--------------------\n",
      "Epoch num: 138\n",
      "  Train Loss: 1.2291\n",
      "  Test Loss:  1.9277\n",
      "  Accuracy:   31.94%\n",
      "--------------------\n",
      "Epoch num: 139\n",
      "  Train Loss: 1.2161\n",
      "  Test Loss:  1.8362\n",
      "  Accuracy:   33.04%\n",
      "--------------------\n",
      "Epoch num: 140\n",
      "  Train Loss: 1.2035\n",
      "  Test Loss:  1.6976\n",
      "  Accuracy:   35.45%\n",
      "--------------------\n",
      "Epoch num: 141\n",
      "  Train Loss: 1.2107\n",
      "  Test Loss:  1.9904\n",
      "  Accuracy:   31.38%\n",
      "--------------------\n",
      "Epoch num: 142\n",
      "  Train Loss: 1.2116\n",
      "  Test Loss:  1.7411\n",
      "  Accuracy:   34.46%\n",
      "--------------------\n",
      "Epoch num: 143\n",
      "  Train Loss: 1.2078\n",
      "  Test Loss:  1.8228\n",
      "  Accuracy:   32.31%\n",
      "--------------------\n",
      "Epoch num: 144\n",
      "  Train Loss: 1.2181\n",
      "  Test Loss:  1.8694\n",
      "  Accuracy:   32.74%\n",
      "--------------------\n",
      "Epoch num: 145\n",
      "  Train Loss: 1.2063\n",
      "  Test Loss:  1.9045\n",
      "  Accuracy:   32.74%\n",
      "--------------------\n",
      "Epoch num: 146\n",
      "  Train Loss: 1.2112\n",
      "  Test Loss:  1.9250\n",
      "  Accuracy:   32.54%\n",
      "--------------------\n",
      "Epoch num: 147\n",
      "  Train Loss: 1.2087\n",
      "  Test Loss:  1.8458\n",
      "  Accuracy:   33.27%\n",
      "--------------------\n",
      "Epoch num: 148\n",
      "  Train Loss: 1.2100\n",
      "  Test Loss:  1.7458\n",
      "  Accuracy:   33.56%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _afterFork at 0x7fe56a3b3740>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/logging/__init__.py\", line 245, in _afterFork\n",
      "    def _afterFork():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 239438, 239439, 239440, 239441, 239442, 239443, 239444, 239445) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/queue.py:209\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m model.train()\n\u001b[32m      4\u001b[39m training_loss = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1434\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1433\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1436\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/python/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1288\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1287\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1289\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 239438, 239439, 239440, 239441, 239442, 239443, 239444, 239445) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for x,y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        training_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in valloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss+=loss.item()\n",
    "            total += y.size(0)\n",
    "            probability, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    if True: \n",
    "        avg_train_loss = training_loss / len(trainloader)\n",
    "        avg_test_loss = test_loss / len(valloader)\n",
    "        accuracy = (100 * correct) / total\n",
    "\n",
    "        print(f\"Epoch num: {i}\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Test Loss:  {avg_test_loss:.4f}\")\n",
    "        print(f\"  Accuracy:   {accuracy:.2f}%\")\n",
    "        print(\"--------------------\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3242e98c-8ec7-44be-b89c-017e08876140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "be7fdce9-45a3-4fd1-b05d-dc6018b9056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32,64,128,256])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [2,4,6])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [16, 64, 128])\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-3, 1e-4, 1e-5])\n",
    "    epochs = trial.suggest_categorical(\"epochs\", [50, 75, 100])\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-2, 1e-3, 1e-4])   \n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3,5,7])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    trainloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    valloader = DataLoader(valDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CnnArchitecture(False, 8, num_layers, hidden_size, kernel_size)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    testloss = []\n",
    "\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        for x,y in trainloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            training_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in valloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                test_loss+=loss.item()\n",
    "                total += y.size(0)\n",
    "                probability, predicted = torch.max(y_pred.data, 1)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                \n",
    "        if i%20==0 or i==epochs-1: \n",
    "            avg_train_loss = training_loss / len(trainloader)\n",
    "            avg_test_loss = test_loss / len(valloader)\n",
    "            accuracy = (100 * correct) / total\n",
    "    \n",
    "            print(f\"Epoch num: {i}\")\n",
    "            print(f\"  Train Loss: {avg_train_loss}\")\n",
    "            print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "            print(f\"  Accuracy:   {accuracy}%\")\n",
    "            print(\"--------------------\")\n",
    "            testloss.append(avg_test_loss)\n",
    "            trial.report(avg_test_loss, i)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return testloss[-1]#want to minimize testloss!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2bbc31b4-fb79-4e11-88c5-429e366555fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:02:16,733] A new study created in memory with name: no-name-1607bd90-eb2a-4e16-948d-619da8e3c268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 2.00931101088113\n",
      "  Test Loss:  2.066826912264029\n",
      "  Accuracy:   17.658730158730158%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.5989997386932373\n",
      "  Test Loss:  1.9629530683159828\n",
      "  Accuracy:   25.363756613756614%\n",
      "--------------------\n",
      "Epoch num: 40\n",
      "  Train Loss: 1.469299106311549\n",
      "  Test Loss:  2.2151202087601027\n",
      "  Accuracy:   22.056878306878307%\n",
      "--------------------\n",
      "Epoch num: 60\n",
      "  Train Loss: 1.4036296089386504\n",
      "  Test Loss:  2.118182343741258\n",
      "  Accuracy:   22.71825396825397%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:15:35,661] Trial 0 finished with value: 2.1473116725683212 and parameters: {'batch_size': 64, 'num_layers': 2, 'hidden_size': 64, 'lr': 0.0001, 'epochs': 75, 'weight_decay': 0.001, 'kernel_size': 5}. Best is trial 0 with value: 2.1473116725683212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 74\n",
      "  Train Loss: 1.3735756814946705\n",
      "  Test Loss:  2.1473116725683212\n",
      "  Accuracy:   22.321428571428573%\n",
      "--------------------\n",
      "Epoch num: 0\n",
      "  Train Loss: 2.0273649605385007\n",
      "  Test Loss:  2.0424024015665054\n",
      "  Accuracy:   18.154761904761905%\n",
      "--------------------\n",
      "Epoch num: 20\n",
      "  Train Loss: 1.3194255900445246\n",
      "  Test Loss:  1.8917801255981128\n",
      "  Accuracy:   26.256613756613756%\n",
      "--------------------\n",
      "Epoch num: 40\n",
      "  Train Loss: 1.212023225372205\n",
      "  Test Loss:  1.8358566612005234\n",
      "  Accuracy:   31.547619047619047%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:25:41,432] Trial 1 finished with value: 1.744110345840454 and parameters: {'batch_size': 64, 'num_layers': 6, 'hidden_size': 64, 'lr': 0.001, 'epochs': 50, 'weight_decay': 0.0001, 'kernel_size': 5}. Best is trial 1 with value: 1.744110345840454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 49\n",
      "  Train Loss: 1.1887231570311065\n",
      "  Test Loss:  1.744110345840454\n",
      "  Accuracy:   30.91931216931217%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1cc632c6-699a-431f-b723-05b2ce5c3e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batch_size: 64\n",
      "    num_layers: 6\n",
      "    hidden_size: 64\n",
      "    lr: 0.001\n",
      "    epochs: 50\n",
      "    weight_decay: 0.0001\n",
      "    kernel_size: 5\n"
     ]
    }
   ],
   "source": [
    "for key, value in study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56bb062b-80ea-459b-a45e-63109741a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now build model with best found params\n",
    "best_params = study.best_params\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "num_layers = best_params[\"num_layers\"]\n",
    "hidden_size = best_params[\"hidden_size\"]\n",
    "lr = best_params[\"lr\"]\n",
    "epochs = best_params[\"epochs\"]\n",
    "kernel_size = best_params[\"kernel_size\"]\n",
    "weight_decay = best_params[\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6d22582e-b8c3-4fe8-9001-fb6969e6978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 0\n",
      "  Train Loss: 2.0322392606403326\n",
      "  Test Loss:  2.06941290696462\n",
      "  Accuracy:   15.211640211640212%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#custom dataset with both train && val\n",
    "compressedtrain = []\n",
    "compressedtrainlabels = []\n",
    "compressedtrain.extend(trainimages_final)\n",
    "compressedtrain.extend(valimages_final)\n",
    "compressedtrainlabels.extend(trainlabel_final)\n",
    "compressedtrainlabels.extend(vallabels_final)\n",
    "compressedDataset =  MyDataset(compressedtrain, compressedtrainlabels, transform_train)\n",
    "\n",
    "\n",
    "\n",
    "trainloader = DataLoader(compressedDataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CnnArchitecture(False, 8, num_layers, hidden_size, kernel_size)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "testloss = []\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for x,y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        training_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in valloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss+=loss.item()\n",
    "            total += y.size(0)\n",
    "            probability, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    if i%20==0 or i==epochs-1: \n",
    "        avg_train_loss = training_loss / len(trainloader)\n",
    "        avg_test_loss = test_loss / len(valloader)\n",
    "        accuracy = (100 * correct) / total\n",
    "\n",
    "        print(f\"Epoch num: {i}\")\n",
    "        print(f\"  Train Loss: {avg_train_loss}\")\n",
    "        print(f\"  Test Loss:  {avg_test_loss}\")\n",
    "        print(f\"  Accuracy:   {accuracy}%\")\n",
    "        print(\"--------------------\")\n",
    "        testloss.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c7437ce1-1889-481c-8104-c62b7e1348dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_emotion_prediction.pkl']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"cnn_emotion_prediction.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "05ea16b3-40d5-40eb-b9c0-cba5c12cc3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = joblib.load('cnn_emotion_prediction.pkl')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe962d-6aa8-4f1e-a14d-ec0be841af26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523d6eb-26e6-4230-8d1f-b742a8233d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc1413-dd23-4b62-a828-7544333c5ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe179a5-67d2-49a1-88d5-77aabbe55192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e86eec-4af7-4ad9-adb3-312c61dcc3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603aa194-00aa-4c55-b143-7161bbb0c8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3cd21-c359-48fb-8416-2e858abd21a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e69732-c599-4cfd-96d3-a432bb80b66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581dd93-71d4-4ee2-8f5c-0d38eb7b3757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c273a-76c6-4563-b0d0-f8ae6ebff95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5dfad-1700-4f1f-8bb2-198185b53ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f2b5e-f30b-41af-afae-f3c90927bed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74ee58-71bc-4ba8-b641-ccc37f8fbe87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383de1cc-fa80-4ecb-ae21-0ee81bb65178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9d2ee-394b-4876-b8eb-f4d6d8bf849e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d084161-14ef-470c-9ed3-d741f1f655ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37aa34-2612-430b-b053-1c70a0eaafe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c66b62-fa3a-4d14-a485-bc2e270fd3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeda0e-1082-4799-a4cd-210688dfde28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1da14-dff2-4554-abd0-a5980f95a99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c556a6-1d4d-4d8f-bb2f-fe955203567d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b4bd8-9dd6-4767-a3d2-15a7fed38c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c4ecb-168e-4f6b-a515-d603e609a708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79ba5974-9ea4-4e19-8d23-3a063fd06815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testrun for prediction\n",
    "img = Image.open('emotionfolder/Train/anger/image0022969.jpg')\n",
    "img = transforms_test(img)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c916d460-fe9e-4b57-9221-c4dd454e0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EmotionMap = {v:k for k,v in Map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fd6b71c2-88e6-47de-a4fc-004337c897e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'contempt': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'happy': 4,\n",
       " 'neutral': 5,\n",
       " 'sad': 6,\n",
       " 'surprise': 7}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmotionMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ca95ab5-eb8b-46d7-b45d-bf491353112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to define this into helper file later on...\n",
    "def Predict(imgpath, model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    PredictionEmotionMap =EmotionMap.copy()\n",
    "    img = Image.open(imgpath)\n",
    "    img = transforms_test(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(img)\n",
    "\n",
    "    prediction_confidence_array = torch.nn.functional.softmax(y_pred, dim=1)[0].cpu().numpy()\n",
    "    for i in range(len(prediction_confidence_array)):\n",
    "        emotion = Map[i]\n",
    "        PredictionEmotionMap[emotion] = prediction_confidence_array[i]\n",
    "\n",
    "    return PredictionEmotionMap\n",
    "    #how would I convert confidence to a 100%scale cause it ain't like that right now no?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "32e1f815-4cbd-4500-9ee0-986e965b1766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': np.float32(0.10275879),\n",
       " 'contempt': np.float32(0.10070733),\n",
       " 'disgust': np.float32(0.09365553),\n",
       " 'fear': np.float32(0.10301596),\n",
       " 'happy': np.float32(0.16819917),\n",
       " 'neutral': np.float32(0.15946205),\n",
       " 'sad': np.float32(0.13645828),\n",
       " 'surprise': np.float32(0.13574292)}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict('emotionfolder/Train/anger/image0022969.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbf3df-f993-425a-8f75-3ac301c60e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
